net: "train_val.prototxt"
display: 20
average_loss: 20
lr_policy: "fixed"
# lr for unnormalized softmax -- see train_val definition
base_lr: 1e-14
# high momentum
momentum: 0.99
# no gradient accumulation
iter_size: 1
max_iter: 80000
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "train"
test_initialization: false